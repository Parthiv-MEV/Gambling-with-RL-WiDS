{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment : Week 2\n",
    "## Finding best policies in simple MDPs\n",
    "\n",
    "Great work making the MDPs in Week 1!\n",
    "\n",
    "In this assignment, we'll use the simplest RL techniques - Policy and Value iteration to find the best policies (which maximize the discounted total reward) in our MDPs from last week.\n",
    "\n",
    "Feel free to use your own MDPs, or import them from the OpenAI Gym library.\n",
    "\n",
    "You can start this assignment during/after reading Grokking Ch-3.\n",
    "\n",
    "For this you have to install gymnasium, which is an API standard for reinforcement learning with a diverse collection of reference environments. This can be easily done by running:\n",
    "\n",
    "    pip install gymnasium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frozen Lake\n",
    "\n",
    "Let's now try to solve the Frozen Lake environment for some cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0 is to import stuff\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from gymnasium.envs.toy_text.frozen_lake import generate_random_map\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRID_SIZE = 4\n",
    "TERMINAL_STATES = {5, 7, 11, 12, 15}\n",
    "ACTIONS = [\"Up\", \"Down\", \"Left\", \"Right\"]\n",
    "\n",
    "# Define the transitions for stochastic behavior\n",
    "PROBABILITIES = {\n",
    "    \"Intended\": 1/3,\n",
    "    \"Left\": 1/3,\n",
    "    \"Right\": 1/3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def left_action(action):\n",
    "    if(action==\"Up\"):\n",
    "        return \"Left\"\n",
    "    elif(action==\"Left\"):\n",
    "        return \"Down\"\n",
    "    elif(action==\"Down\"):\n",
    "        return \"Right\"\n",
    "    elif(action==\"Right\"):\n",
    "        return \"Up\"\n",
    "    \n",
    "def right_action(action):\n",
    "    if(action==\"Left\"):\n",
    "        return \"Up\"\n",
    "    elif(action==\"Down\"):\n",
    "        return \"Left\"\n",
    "    elif(action==\"Right\"):\n",
    "        return \"Down\"\n",
    "    elif(action==\"Up\"):\n",
    "        return \"Right\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'Down': [(0.3333333333333333, 4, 0, False),\n",
      "              (0.3333333333333333, 1, 0, False),\n",
      "              (0.3333333333333333, 0, 0, False)],\n",
      "     'Left': [(0.3333333333333333, 0, 0, False),\n",
      "              (0.3333333333333333, 4, 0, False),\n",
      "              (0.3333333333333333, 0, 0, False)],\n",
      "     'Right': [(0.3333333333333333, 1, 0, False),\n",
      "               (0.3333333333333333, 0, 0, False),\n",
      "               (0.3333333333333333, 4, 0, False)],\n",
      "     'Up': [(0.3333333333333333, 0, 0, False),\n",
      "            (0.3333333333333333, 0, 0, False),\n",
      "            (0.3333333333333333, 1, 0, False)]},\n",
      " 1: {'Down': [(0.3333333333333333, 5, 0, True),\n",
      "              (0.3333333333333333, 2, 0, False),\n",
      "              (0.3333333333333333, 0, 0, False)],\n",
      "     'Left': [(0.3333333333333333, 0, 0, False),\n",
      "              (0.3333333333333333, 5, 0, True),\n",
      "              (0.3333333333333333, 1, 0, False)],\n",
      "     'Right': [(0.3333333333333333, 2, 0, False),\n",
      "               (0.3333333333333333, 1, 0, False),\n",
      "               (0.3333333333333333, 5, 0, True)],\n",
      "     'Up': [(0.3333333333333333, 1, 0, False),\n",
      "            (0.3333333333333333, 0, 0, False),\n",
      "            (0.3333333333333333, 2, 0, False)]},\n",
      " 2: {'Down': [(0.3333333333333333, 6, 0, False),\n",
      "              (0.3333333333333333, 3, 0, False),\n",
      "              (0.3333333333333333, 1, 0, False)],\n",
      "     'Left': [(0.3333333333333333, 1, 0, False),\n",
      "              (0.3333333333333333, 6, 0, False),\n",
      "              (0.3333333333333333, 2, 0, False)],\n",
      "     'Right': [(0.3333333333333333, 3, 0, False),\n",
      "               (0.3333333333333333, 2, 0, False),\n",
      "               (0.3333333333333333, 6, 0, False)],\n",
      "     'Up': [(0.3333333333333333, 2, 0, False),\n",
      "            (0.3333333333333333, 1, 0, False),\n",
      "            (0.3333333333333333, 3, 0, False)]},\n",
      " 3: {'Down': [(0.3333333333333333, 7, 0, True),\n",
      "              (0.3333333333333333, 3, 0, False),\n",
      "              (0.3333333333333333, 2, 0, False)],\n",
      "     'Left': [(0.3333333333333333, 2, 0, False),\n",
      "              (0.3333333333333333, 7, 0, True),\n",
      "              (0.3333333333333333, 3, 0, False)],\n",
      "     'Right': [(0.3333333333333333, 3, 0, False),\n",
      "               (0.3333333333333333, 3, 0, False),\n",
      "               (0.3333333333333333, 7, 0, True)],\n",
      "     'Up': [(0.3333333333333333, 3, 0, False),\n",
      "            (0.3333333333333333, 2, 0, False),\n",
      "            (0.3333333333333333, 3, 0, False)]},\n",
      " 4: {'Down': [(0.3333333333333333, 8, 0, False),\n",
      "              (0.3333333333333333, 5, 0, True),\n",
      "              (0.3333333333333333, 4, 0, False)],\n",
      "     'Left': [(0.3333333333333333, 4, 0, False),\n",
      "              (0.3333333333333333, 8, 0, False),\n",
      "              (0.3333333333333333, 0, 0, False)],\n",
      "     'Right': [(0.3333333333333333, 5, 0, True),\n",
      "               (0.3333333333333333, 0, 0, False),\n",
      "               (0.3333333333333333, 8, 0, False)],\n",
      "     'Up': [(0.3333333333333333, 0, 0, False),\n",
      "            (0.3333333333333333, 4, 0, False),\n",
      "            (0.3333333333333333, 5, 0, True)]},\n",
      " 5: {'Down': [(1.0, 5, 0, True)],\n",
      "     'Left': [(1.0, 5, 0, True)],\n",
      "     'Right': [(1.0, 5, 0, True)],\n",
      "     'Up': [(1.0, 5, 0, True)]},\n",
      " 6: {'Down': [(0.3333333333333333, 10, 0, False),\n",
      "              (0.3333333333333333, 7, 0, True),\n",
      "              (0.3333333333333333, 5, 0, True)],\n",
      "     'Left': [(0.3333333333333333, 5, 0, True),\n",
      "              (0.3333333333333333, 10, 0, False),\n",
      "              (0.3333333333333333, 2, 0, False)],\n",
      "     'Right': [(0.3333333333333333, 7, 0, True),\n",
      "               (0.3333333333333333, 2, 0, False),\n",
      "               (0.3333333333333333, 10, 0, False)],\n",
      "     'Up': [(0.3333333333333333, 2, 0, False),\n",
      "            (0.3333333333333333, 5, 0, True),\n",
      "            (0.3333333333333333, 7, 0, True)]},\n",
      " 7: {'Down': [(1.0, 7, 0, True)],\n",
      "     'Left': [(1.0, 7, 0, True)],\n",
      "     'Right': [(1.0, 7, 0, True)],\n",
      "     'Up': [(1.0, 7, 0, True)]},\n",
      " 8: {'Down': [(0.3333333333333333, 12, 0, True),\n",
      "              (0.3333333333333333, 9, 0, False),\n",
      "              (0.3333333333333333, 8, 0, False)],\n",
      "     'Left': [(0.3333333333333333, 8, 0, False),\n",
      "              (0.3333333333333333, 12, 0, True),\n",
      "              (0.3333333333333333, 4, 0, False)],\n",
      "     'Right': [(0.3333333333333333, 9, 0, False),\n",
      "               (0.3333333333333333, 4, 0, False),\n",
      "               (0.3333333333333333, 12, 0, True)],\n",
      "     'Up': [(0.3333333333333333, 4, 0, False),\n",
      "            (0.3333333333333333, 8, 0, False),\n",
      "            (0.3333333333333333, 9, 0, False)]},\n",
      " 9: {'Down': [(0.3333333333333333, 13, 0, False),\n",
      "              (0.3333333333333333, 10, 0, False),\n",
      "              (0.3333333333333333, 8, 0, False)],\n",
      "     'Left': [(0.3333333333333333, 8, 0, False),\n",
      "              (0.3333333333333333, 13, 0, False),\n",
      "              (0.3333333333333333, 5, 0, True)],\n",
      "     'Right': [(0.3333333333333333, 10, 0, False),\n",
      "               (0.3333333333333333, 5, 0, True),\n",
      "               (0.3333333333333333, 13, 0, False)],\n",
      "     'Up': [(0.3333333333333333, 5, 0, True),\n",
      "            (0.3333333333333333, 8, 0, False),\n",
      "            (0.3333333333333333, 10, 0, False)]},\n",
      " 10: {'Down': [(0.3333333333333333, 14, 0, False),\n",
      "               (0.3333333333333333, 11, 0, True),\n",
      "               (0.3333333333333333, 9, 0, False)],\n",
      "      'Left': [(0.3333333333333333, 9, 0, False),\n",
      "               (0.3333333333333333, 14, 0, False),\n",
      "               (0.3333333333333333, 6, 0, False)],\n",
      "      'Right': [(0.3333333333333333, 11, 0, True),\n",
      "                (0.3333333333333333, 6, 0, False),\n",
      "                (0.3333333333333333, 14, 0, False)],\n",
      "      'Up': [(0.3333333333333333, 6, 0, False),\n",
      "             (0.3333333333333333, 9, 0, False),\n",
      "             (0.3333333333333333, 11, 0, True)]},\n",
      " 11: {'Down': [(1.0, 11, 0, True)],\n",
      "      'Left': [(1.0, 11, 0, True)],\n",
      "      'Right': [(1.0, 11, 0, True)],\n",
      "      'Up': [(1.0, 11, 0, True)]},\n",
      " 12: {'Down': [(1.0, 12, 0, True)],\n",
      "      'Left': [(1.0, 12, 0, True)],\n",
      "      'Right': [(1.0, 12, 0, True)],\n",
      "      'Up': [(1.0, 12, 0, True)]},\n",
      " 13: {'Down': [(0.3333333333333333, 13, 0, False),\n",
      "               (0.3333333333333333, 14, 0, False),\n",
      "               (0.3333333333333333, 12, 0, True)],\n",
      "      'Left': [(0.3333333333333333, 12, 0, True),\n",
      "               (0.3333333333333333, 13, 0, False),\n",
      "               (0.3333333333333333, 9, 0, False)],\n",
      "      'Right': [(0.3333333333333333, 14, 0, False),\n",
      "                (0.3333333333333333, 9, 0, False),\n",
      "                (0.3333333333333333, 13, 0, False)],\n",
      "      'Up': [(0.3333333333333333, 9, 0, False),\n",
      "             (0.3333333333333333, 12, 0, True),\n",
      "             (0.3333333333333333, 14, 0, False)]},\n",
      " 14: {'Down': [(0.3333333333333333, 14, 0, False),\n",
      "               (0.3333333333333333, 15, 0, True),\n",
      "               (0.3333333333333333, 13, 0, False)],\n",
      "      'Left': [(0.3333333333333333, 13, 0, False),\n",
      "               (0.3333333333333333, 14, 0, False),\n",
      "               (0.3333333333333333, 10, 0, False)],\n",
      "      'Right': [(0.3333333333333333, 15, 0, True),\n",
      "                (0.3333333333333333, 10, 0, False),\n",
      "                (0.3333333333333333, 14, 0, False)],\n",
      "      'Up': [(0.3333333333333333, 10, 0, False),\n",
      "             (0.3333333333333333, 13, 0, False),\n",
      "             (0.3333333333333333, 15, 0, True)]},\n",
      " 15: {'Down': [(1.0, 15, 0, True)],\n",
      "      'Left': [(1.0, 15, 0, True)],\n",
      "      'Right': [(1.0, 15, 0, True)],\n",
      "      'Up': [(1.0, 15, 0, True)]}}\n"
     ]
    }
   ],
   "source": [
    "def get_next_state(state, action):\n",
    "    \"\"\"Determines the next state based on the current state and action.\"\"\"\n",
    "    row, col = divmod(state, GRID_SIZE)\n",
    "    \n",
    "    \n",
    "    if action == \"Up\":\n",
    "        row = max(row - 1, 0)\n",
    "    elif action == \"Down\":\n",
    "        row = min(row + 1, GRID_SIZE - 1)\n",
    "    elif action == \"Left\":\n",
    "        col = max(col - 1, 0)\n",
    "    elif action == \"Right\":\n",
    "        col = min(col + 1, GRID_SIZE - 1)\n",
    "\n",
    "    return row * GRID_SIZE + col\n",
    "\n",
    "def generate_transitions(state):\n",
    "    \"\"\"Generates transitions for a given state.\"\"\"\n",
    "    if state in TERMINAL_STATES:\n",
    "        return {action: [(1.0, state, 0, True)] for action in ACTIONS}  # Stays in the same state\n",
    "\n",
    "    transitions = {}\n",
    "    for action in ACTIONS:\n",
    "        intended_state = get_next_state(state, action)\n",
    "        left_state = get_next_state(state, left_action(action))\n",
    "        right_state = get_next_state(state, right_action(action))\n",
    "\n",
    "        transitions[action] = [\n",
    "            (PROBABILITIES[\"Intended\"], intended_state, 0, intended_state in TERMINAL_STATES),\n",
    "            (PROBABILITIES[\"Left\"], left_state, 0, left_state in TERMINAL_STATES),\n",
    "            (PROBABILITIES[\"Right\"], right_state, 0, right_state in TERMINAL_STATES)\n",
    "        ]\n",
    "\n",
    "    return transitions\n",
    "\n",
    "# Construct the MDP dictionary\n",
    "mdp = {}\n",
    "for state in range(GRID_SIZE * GRID_SIZE):\n",
    "    mdp[state] = generate_transitions(state)\n",
    "\n",
    "# Example output\n",
    "pprint(mdp)\n",
    "\n",
    "from gymnasium.envs.toy_text.frozen_lake import generate_random_map\n",
    "\n",
    "# Step 1: Initialize the FrozenLake environment\n",
    "env = gym.make('FrozenLake-v1', desc=None, map_name=\"4x4\", is_slippery=True)\n",
    "env = env.unwrapped\n",
    "mdp_transitions = env.P\n",
    "init_state = env.reset()\n",
    "goal_state = 15\n",
    "\n",
    "# Step 2: Define policy\n",
    "LEFT, DOWN, RIGHT, UP = range(4)\n",
    "pi = {\n",
    "    0: RIGHT, 1: RIGHT, 2: DOWN, 3: LEFT,\n",
    "    4: DOWN, 5: LEFT, 6: DOWN, 7: LEFT,\n",
    "    8: RIGHT, 9: RIGHT, 10: DOWN, 11: LEFT,\n",
    "    12: LEFT, 13: RIGHT, 14: RIGHT, 15: LEFT\n",
    "}\n",
    "\n",
    "# Step 3: Initialize value function\n",
    "val = {state: 0 for state in mdp_transitions}\n",
    "val[5], val[7], val[11], val[12], val[15] = 0, 0, 0, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_value_fn(val, mdp, pi, gamma=1.0):\n",
    "    new_val = {}\n",
    "    for state in mdp:\n",
    "        action = pi[state]\n",
    "        new_val[state] = sum(prob * (reward + gamma * val[next_state])\n",
    "                             for prob, next_state, reward, _ in mdp[state][action])\n",
    "    return new_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_evaluation(val, mdp, pi, epsilon=1e-10, gamma=1.0):\n",
    "    count = 0\n",
    "    while True:\n",
    "        new_val = get_new_value_fn(val, mdp, pi, gamma)\n",
    "        delta = max(abs(new_val[s] - val[s]) for s in mdp)\n",
    "        val = new_val\n",
    "        count += 1\n",
    "        if delta < epsilon:\n",
    "            break\n",
    "    return val, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_improvement(val, mdp, pi, gamma=1.0):\n",
    "    new_pi = {}\n",
    "    q = {}\n",
    "    for state in mdp:\n",
    "        q[state] = {}\n",
    "        for action in range(4):\n",
    "            q[state][action] = sum(prob * (reward + gamma * val[next_state])\n",
    "                                   for prob, next_state, reward, _ in mdp[state][action])\n",
    "        new_pi[state] = max(q[state], key=q[state].get)\n",
    "    return new_pi, q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_iteration(mdp, epsilon=1e-10, gamma=1.0):\n",
    "    pi = {s: np.random.choice(range(4)) for s in mdp}\n",
    "    val = {s: 0 for s in mdp}\n",
    "    count = 0\n",
    "    while True:\n",
    "        val, _ = policy_evaluation(val, mdp, pi, epsilon, gamma)\n",
    "        new_pi, _ = policy_improvement(val, mdp, pi, gamma)\n",
    "        count += 1\n",
    "        if new_pi == pi:\n",
    "            break\n",
    "        pi = new_pi\n",
    "    return pi, val, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(mdp, gamma=1.0, epsilon=1e-10):\n",
    "    val = {s: 0 for s in mdp}\n",
    "    count = 0\n",
    "    while True:\n",
    "        new_val = {s: max(sum(prob * (reward + gamma * val[next_state])\n",
    "                              for prob, next_state, reward, _ in mdp[s][a])\n",
    "                           for a in range(4)) for s in mdp}\n",
    "        delta = max(abs(new_val[s] - val[s]) for s in mdp)\n",
    "        val = new_val\n",
    "        count += 1\n",
    "        if delta < epsilon:\n",
    "            break\n",
    "    pi = {s: max(range(4), key=lambda a: sum(prob * (reward + gamma * val[next_state])\n",
    "                                             for prob, next_state, reward, _ in mdp[s][a]))\n",
    "          for s in mdp}\n",
    "    return pi, val, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_policy(policy, env):\n",
    "    action_symbols = {0: '←', 1: '↓', 2: '→', 3: '↑'}\n",
    "    grid_size = env.desc.shape\n",
    "    policy_symbols = np.array([action_symbols[policy[cell]] for cell in range(len(policy))])\n",
    "    policy_grid = policy_symbols.reshape(grid_size)\n",
    "    print(\"Policy Grid:\")\n",
    "    for row in policy_grid:\n",
    "        print(\" \".join(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_policy(pi, env, goalstate):\n",
    "    successes = 0\n",
    "    for _ in range(100):\n",
    "        state, _ = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = pi[state]\n",
    "            state, _, done, _, _ = env.step(action)\n",
    "        if state == goalstate:\n",
    "            successes += 1\n",
    "    return successes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy Iteration:\n",
      "Policy Grid:\n",
      "← ↑ ↑ ↑\n",
      "← ← ← ←\n",
      "↑ ↓ ← ←\n",
      "← → ↓ ←\n",
      "Converged in 7 iterations.\n",
      "\n",
      "Value Iteration:\n",
      "Policy Grid:\n",
      "← ↑ ↑ ↑\n",
      "← ← ← ←\n",
      "↑ ↓ ← ←\n",
      "← → ↓ ←\n",
      "Converged in 806 iterations.\n",
      "\n",
      "Policy Iteration Success Rate: 77/100\n",
      "Value Iteration Success Rate: 84/100\n"
     ]
    }
   ],
   "source": [
    "pi1, val1, count1 = policy_iteration(mdp_transitions)\n",
    "pi2, val2, count2 = value_iteration(mdp_transitions)\n",
    "\n",
    "# Print results\n",
    "print(\"Policy Iteration:\")\n",
    "print_policy(pi1, env)\n",
    "print(f\"Converged in {count1} iterations.\")\n",
    "\n",
    "print(\"\\nValue Iteration:\")\n",
    "print_policy(pi2, env)\n",
    "print(f\"Converged in {count2} iterations.\")\n",
    "\n",
    "# Test policies\n",
    "success1 = test_policy(pi1, env, goal_state)\n",
    "success2 = test_policy(pi2, env, goal_state)\n",
    "print(f\"\\nPolicy Iteration Success Rate: {success1}/100\")\n",
    "print(f\"Value Iteration Success Rate: {success2}/100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also write a function `test_policy()` to test your policy after training to find the number of times you reached the goal state"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
